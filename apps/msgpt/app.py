from __future__ import annotations
import os
import sys
from functools import partial

import gradio as gr
from dotenv import load_dotenv
from gradio_chatbot import ChatBot
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm import LLMFactory
from predict import stream_predict, upload_image

from modelscope.utils.config import Config

load_dotenv('../../config/.env', override=True)

os.environ['TOOL_CONFIG_FILE'] = '../../config/cfg_tool_template.json'
os.environ['MODEL_CONFIG_FILE'] = '../../config/cfg_model_template.json'
os.environ['OUTPUT_FILE_DIRECTORY'] = './tmp'

with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), 'r',
        encoding='utf-8') as f:
    MAIN_CSS_CODE = f.read()

with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:

    upload_image_url = gr.State('')

    # agent å¯¹è±¡
    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')
    model_cfg_file = os.getenv('MODEL_CONFIG_FILE')

    model_cfg = Config.from_file(model_cfg_file)
    tool_cfg = Config.from_file(tool_cfg_file)

    model_name = 'modelscope-agent-qwen-7b'

    llm = LLMFactory.build_llm(model_name, model_cfg)
    agent = AgentExecutor(llm, tool_cfg)

    stream_predict_p = partial(stream_predict, agent=agent)

    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">ModelScopeGPT</h1>"""
        )
        status_display = gr.HTML(
            '', elem_id='status_display', visible=False, show_label=False)

    with gr.Row(elem_id='container_row').style(equal_height=True):

        with gr.Column(
                scale=8,
                elem_classes=['chatInterface', 'chatDialog', 'chatContent']):
            with gr.Row(elem_id='chat-container'):
                chatbot = ChatBot(
                    elem_id='chatbot',
                    elem_classes=['markdown-body'],
                    show_label=False)
                chatbot_classic = gr.Textbox(
                    lines=20,
                    visible=False,
                    interactive=False,
                    label='classic_chatbot',
                    elem_id='chatbot_classic')
            with gr.Row(elem_id='chat-bottom-container'):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        'æ¸…é™¤', elem_id='clear_session_button')
                with gr.Column(min_width=100, scale=1):
                    upload_button = gr.UploadButton(
                        'ä¸Šä¼ å›¾ç‰‡', file_types=['image'])
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder='å’Œæˆ‘èŠèŠå§ï½',
                        elem_id='chat-input').style(container=False)
                    uploaded_image_box = gr.HTML(
                        '', visible=False, show_label=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button('å‘é€', variant='primary')
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        'é‡æ–°ç”Ÿæˆ', elem_id='regenerate_button')

        with gr.Column(min_width=470, scale=4, elem_id='settings'):
            icon_path = 'https://img.alicdn.com/imgextra/i4/O1CN01kpkVcX1wSCO362MH4_!!6000000006306-1-tps-805-805.gif'
            info_text = 'æˆ‘æ˜¯ModelScopeGPTï¼ˆé­”æ­GPTï¼‰ï¼Œ æ˜¯ä¸€ä¸ªå¤§å°æ¨¡å‹ååŒçš„agentç³»ç»Ÿã€‚\
                æˆ‘å…·å¤‡å¤šç§èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡å¤§æ¨¡å‹åšä¸­æ¢ï¼ˆcontrollerï¼‰ï¼Œæ¥æ§åˆ¶é­”æ­ç¤¾åŒºçš„å„ç§å¤šæ¨¡æ€æ¨¡å‹apiå›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚\
                é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘è¿˜é›†æˆäº†çŸ¥è¯†åº“æ£€ç´¢å¼•æ“ï¼Œå¯ä»¥è§£ç­”ç”¨æˆ·åœ¨é­”æ­ç¤¾åŒºä½¿ç”¨æ¨¡å‹é‡åˆ°çš„é—®é¢˜ä»¥åŠæ¨¡å‹çŸ¥è¯†ç›¸å…³é—®ç­”ã€‚'

            gr.HTML(f"""
                <div class="robot-info">
                    <img src="{icon_path}"</img>
                    <div class="robot-info-text">
                        "{info_text}"
                    </div>
                </div>
            """)

            gr.Examples(
                examples=[
                    'å†™ä¸€é¦–ç®€çŸ­çš„å¤å¤©è½æ—¥çš„è¯—',
                    'è®²ä¸€ä¸ªå°ç”·å­©çš„æ•…äº‹ï¼Œ20å­—å·¦å³',
                    'ç”¨ç”·å£°è¯»å‡ºæ¥',
                    'ç”Ÿæˆä¸ªå›¾ç‰‡çœ‹çœ‹',
                    'ä»ä¸‹é¢çš„åœ°å€ï¼Œæ‰¾åˆ°çœå¸‚åŒºç­‰å…ƒç´ ï¼Œåœ°å€ï¼šæµ™æ±Ÿæ­å·å¸‚æ±Ÿå¹²åŒºä¹å ¡é•‡ä¸‰æ‘æ‘ä¸€åŒº',
                ],
                inputs=[user_input],
                examples_per_page=20,
                label='ç¤ºä¾‹',
                elem_id='chat-examples')

    stream_predict_input = [chatbot, user_input, upload_image_url]
    stream_predict_output = [chatbot, status_display]

    clean_outputs = [gr.update(value=''), '']
    clean_outputs_target = [user_input, uploaded_image_box]

    user_input.submit(
        stream_predict_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    submitBtn.click(
        stream_predict_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    submitBtn.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        stream_predict_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    upload_button.upload(upload_image, upload_button,
                         [uploaded_image_box, upload_image_url])

    def clear_session():
        agent.reset()
        return {
            chatbot: gr.update(value=[]),
            uploaded_image_box: '',
            upload_image_url: '',
        }

    clear_session_button.click(
        fn=clear_session,
        inputs=[],
        outputs=[chatbot, uploaded_image_box, upload_image_url])

    demo.title = 'ModelScopeGPT ğŸ'
    demo.queue(concurrency_count=10, status_update_rate='auto', api_open=False)
    demo.launch(show_api=False, share=False)
