from __future__ import annotations
import os
import sys
from functools import partial

import gradio as gr
from dotenv import load_dotenv
from gradio_chatbot import ChatBot
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm.ms_gpt import ModelScopeGPT
from modelscope_agent.prompt import MSPromptGenerator, PromptGenerator
from modelscope_agent.retrieve import ToolRetrieval
from predict import generate_story, stream_predict

from modelscope.utils.config import Config

sys.path.append('../../')
load_dotenv('config/.env', override=True)

SYSTEM_PROMPT = "<|system|>:ä½ æ˜¯Story Agentï¼Œæ˜¯ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¾“å…¥è‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„ç»˜æœ¬ã€‚"

INSTRUCTION_TEMPLATE = """å½“å‰å¯¹è¯å¯ä»¥ä½¿ç”¨çš„æ’ä»¶ä¿¡æ¯å¦‚ä¸‹ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ’ä»¶æ¥è§£å†³å½“å‰ç”¨æˆ·é—®é¢˜ã€‚è‹¥éœ€è¦è°ƒç”¨æ’ä»¶ï¼Œåˆ™éœ€è¦å°†æ’ä»¶è°ƒç”¨è¯·æ±‚æŒ‰ç…§jsonæ ¼å¼ç»™å‡ºï¼Œå¿…é¡»åŒ…å«api_nameã€parameterså­—æ®µï¼Œå¹¶åœ¨å…¶å‰åä½¿ç”¨<|startofthink|>å’Œ<|endofthink|>ä½œä¸ºæ ‡å¿—ã€‚\
ç„¶åä½ éœ€è¦æ ¹æ®æ’ä»¶APIè°ƒç”¨ç»“æœç”Ÿæˆåˆç†çš„ç­”å¤ï¼› è‹¥éœ€è¦ç”Ÿæˆæ•…äº‹æƒ…èŠ‚ï¼Œè¯·åœ¨æ¯ä¸€å¹•çš„å¼€å§‹ç”¨1, 2, 3...æ ‡è®°ã€‚\n\n<tool_list>"""

with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), "r",
        encoding="utf-8") as f:
    MAIN_CSS_CODE = f.read()

with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:

    max_scene = 4

    history = gr.State([])
    debug_info = gr.State([])

    # agent å¯¹è±¡

    model_cfg_file = os.getenv('LLM_CONFIG_FILE')
    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')

    model_cfg = Config.from_file(model_cfg_file)
    tool_cfg = Config.from_file(tool_cfg_file)

    retrieve = ToolRetrieval(top_k=1)
    prompt_generator = MSPromptGenerator(
        system_template=SYSTEM_PROMPT,
        instruction_template=INSTRUCTION_TEMPLATE)

    llm = ModelScopeGPT(model_cfg)
    agent = AgentExecutor(llm, tool_cfg, tool_retrieval=retrieve)

    generate_story_p = partial(
        generate_story, max_scene=max_scene, agent=agent)

    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">ModelScopeGPT</h1>"""
        )
        status_display = gr.HTML(
            "", elem_id="status_display", visible=False, show_label=False)

    with gr.Row(elem_id="container_row").style(equal_height=True):

        with gr.Column(
                scale=8,
                elem_classes=["chatInterface", "chatDialog", "chatContent"]):
            with gr.Row(elem_id="chat-container"):
                chatbot = ChatBot(
                    elem_id="chatbot",
                    elem_classes=["markdown-body"],
                    show_label=False)
                chatbot_classic = gr.Textbox(
                    lines=20,
                    visible=False,
                    interactive=False,
                    label='classic_chatbot',
                    elem_id='chatbot_classic')
            with gr.Row(elem_id="chat-bottom-container"):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        "æ¸…é™¤", elem_id='clear_session_button')
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder="è¯·è¾“å…¥ä½ æƒ³è¦ç”Ÿæˆçš„æ•…äº‹æƒ…èŠ‚å§ï½",
                        elem_id="chat-input").style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        "é‡æ–°ç”Ÿæˆ", elem_id='regenerate_button')

        with gr.Column(min_width=470, scale=4, elem_id='settings'):
            gr.HTML("""
                <div class="robot-info">
                    <img src="https://img.alicdn.com/\
                    imgextra/i4/O1CN01kpkVcX1wSCO362MH4_!!6000000006306-1-tps-805-805.gif"></img>
                    <div class="robot-info-text">
                        æˆ‘æ˜¯story agentã€‚
                    </div>
                </div>
            """)

            gr.Examples(
                examples=[
                    'å—¨ï¼Œstoryagentï¼Œæˆ‘æ­£åœ¨ä¸ºä¸€ä¸ªæ–°çš„ç”µå­ç»˜æœ¬æ„æ€ä¸€ä¸ªæ•…äº‹ã€‚æˆ‘å¸Œæœ›è¿™æ˜¯ä¸€ä¸ªå…³äºå‹è°Šå’Œå†’é™©çš„æ•…äº‹ï¼Œä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œåˆ†æˆä¸‰å¹•æ¥ç”Ÿæˆã€‚',
                    'ä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œåˆ†æˆ2å¹•æ¥ç”Ÿæˆã€‚', 'ä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œ',
                    'å—¨ï¼Œstoryagentï¼Œæˆ‘æ­£åœ¨ä¸ºä¸€ä¸ªæ–°çš„ç”µå­ç»˜æœ¬æ„æ€ä¸€ä¸ªæ•…äº‹ã€‚æˆ‘å¸Œæœ›è¿™æ˜¯ä¸€ä¸ªå…³äºå‹è°Šå’Œå†’é™©çš„æ•…äº‹ï¼Œä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ã€‚'
                ],
                inputs=[user_input],
                examples_per_page=20,
                label="ç¤ºä¾‹",
                elem_id="chat-examples")

            steps = gr.Slider(
                minimum=1,
                maximum=max_scene,
                value=1,
                step=1,
                label='ç”Ÿæˆç»˜æœ¬çš„æ•°ç›®',
                interactive=True)

            output_image = [None] * max_scene

            for i in range(0, max_scene, 2):
                with gr.Row():
                    output_image[i] = gr.Image(
                        label=f'ç»˜æœ¬å›¾ç‰‡{i}', interactive=False, height=200)
                    output_image[i + 1] = gr.Image(
                        label=f'ç»˜æœ¬å›¾ç‰‡{i+1}', interactive=False, height=200)

    stream_predict_input = [chatbot, user_input, steps]
    stream_predict_output = [chatbot, *output_image, status_display]

    clean_outputs = [''] + [None] * max_scene
    clean_outputs_target = [user_input, *output_image]

    user_input.submit(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    submitBtn.click(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    submitBtn.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    def clear_session():
        agent.reset()
        return {
            chatbot: gr.update(value=[]),
            history: [],
            debug_info: [],
        }

    clear_session_button.click(
        fn=clear_session, inputs=[], outputs=[chatbot, history, debug_info])
    clear_session_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    demo.title = "StoryAgent ğŸ"
    demo.queue(concurrency_count=10, status_update_rate='auto', api_open=False)
    demo.launch(show_api=False, share=True)
