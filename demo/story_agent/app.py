from __future__ import annotations
import os
import sys
from functools import partial

import gradio as gr
from dotenv import load_dotenv
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm import LLMFactory
from modelscope_agent.prompt import MSPromptGenerator, PromptGenerator
from modelscope_agent.retrieve import ToolRetrieval
from predict import generate_story

from modelscope.utils.config import Config

sys.path.append('../../')

SYSTEM_PROMPT = "<|system|>:ä½ æ˜¯Story Agentï¼Œæ˜¯ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¾“å…¥è‡ªåŠ¨ç”Ÿæˆç›¸åº”çš„ç»˜æœ¬ã€‚"

INSTRUCTION_TEMPLATE = """å½“å‰å¯¹è¯å¯ä»¥ä½¿ç”¨çš„æ’ä»¶ä¿¡æ¯å¦‚ä¸‹ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ’ä»¶æ¥è§£å†³å½“å‰ç”¨æˆ·é—®é¢˜ã€‚è‹¥éœ€è¦è°ƒç”¨æ’ä»¶ï¼Œåˆ™éœ€è¦å°†æ’ä»¶è°ƒç”¨è¯·æ±‚æŒ‰ç…§jsonæ ¼å¼ç»™å‡ºï¼Œå¿…é¡»åŒ…å«api_nameã€parameterså­—æ®µï¼Œå¹¶åœ¨å…¶å‰åä½¿ç”¨<|startofthink|>å’Œ<|endofthink|>ä½œä¸ºæ ‡å¿—ã€‚\
ç„¶åä½ éœ€è¦æ ¹æ®æ’ä»¶APIè°ƒç”¨ç»“æœç”Ÿæˆåˆç†çš„ç­”å¤ï¼› è‹¥éœ€è¦ç”Ÿæˆæ•…äº‹æƒ…èŠ‚ï¼Œè¯·æŒ‰ç…§å¦‚ä¸‹çš„æ ¼å¼ç”Ÿæˆï¼š
1. ç¬¬ä¸€éƒ¨åˆ†å†…å®¹ã€‚
2. ç¬¬äºŒéƒ¨åˆ†å†…å®¹ã€‚
...
\n\n<tool_list>"""

MAX_SCENE = 4

# sys.path.append('../../')
load_dotenv('../../config/.env', override=True)

os.environ['TOOL_CONFIG_FILE'] = '../../config/cfg_tool_template.json'
os.environ['MODEL_CONFIG_FILE'] = '../../config/cfg_model_template.json'
os.environ['OUTPUT_FILE_DIRECTORY'] = './tmp'

with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), "r",
        encoding="utf-8") as f:
    MAIN_CSS_CODE = f.read()

with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:

    max_scene = MAX_SCENE

    # agent å¯¹è±¡åˆå§‹åŒ–

    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')
    model_cfg_file = os.getenv('MODEL_CONFIG_FILE')

    tool_cfg = Config.from_file(tool_cfg_file)
    # model_name = 'ms_gpt'
    model_cfg = Config.from_file(model_cfg_file)

    model_name = 'openai'
    # model_cfg = {
    #     'modelscope-agent-qwen-7b': {
    #         'model_id': 'damo/MSAgent-Qwen-7B',
    #         'model_revision': 'v1.0.2',
    #         'use_raw_generation_config': True,
    #         'custom_chat': True
    #     }
    # }

    retrieve = ToolRetrieval(top_k=1)
    prompt_generator = MSPromptGenerator(
        system_template=SYSTEM_PROMPT,
        instruction_template=INSTRUCTION_TEMPLATE)

    llm = LLMFactory.build_llm(model_name, model_cfg)
    agent = AgentExecutor(
        llm,
        tool_cfg,
        prompt_generator=prompt_generator,
        tool_retrieval=retrieve)

    generate_story_p = partial(
        generate_story, max_scene=max_scene, agent=agent)

    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">ModelScopeGPT</h1>"""
        )
        status_display = gr.HTML(
            "", elem_id="status_display", visible=False, show_label=False)

    with gr.Row(elem_id="container_row").style(equal_height=True):

        with gr.Column(
                scale=8,
                elem_classes=["chatInterface", "chatDialog", "chatContent"]):
            # with gr.Column(elem_id="chat-container"):
            output_image = [None] * max_scene
            output_text = [None] * max_scene

            for i in range(0, max_scene, 2):
                with gr.Row():
                    with gr.Column():
                        output_image[i] = gr.Image(
                            label=f'ç»˜æœ¬å›¾ç‰‡{i + 1}',
                            interactive=False,
                            height=200)
                        output_text[i] = gr.Textbox(
                            label=f'æ•…äº‹æƒ…èŠ‚{i + 1}', lines=4, interactive=False)
                    with gr.Column():
                        output_image[i + 1] = gr.Image(
                            label=f'ç»˜æœ¬å›¾ç‰‡{i +2}', interactive=False, height=200)
                        output_text[i + 1] = gr.Textbox(
                            label=f'æ•…äº‹æƒ…èŠ‚{i + 2}', lines=4, interactive=False)

        with gr.Column(min_width=470, scale=4, elem_id='settings'):
            gr.HTML("""
                <div class="robot-info">
                    <img src="https://img.alicdn.com/imgextra/i4/\
                    O1CN01kpkVcX1wSCO362MH4_!!6000000006306-1-tps-805-805.gif"></img>
                    <div class="robot-info-text">
                        æˆ‘æ˜¯story agentã€‚
                    </div>
                </div>
            """)

            with gr.Row(elem_id="chat-bottom-container"):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        "æ¸…é™¤", elem_id='clear_session_button')
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder="è¯·è¾“å…¥ä½ æƒ³è¦ç”Ÿæˆçš„æ•…äº‹æƒ…èŠ‚å§ï½",
                        elem_id="chat-input").style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        "é‡æ–°ç”Ÿæˆ", elem_id='regenerate_button')

            gr.Examples(
                examples=[
                    'å—¨ï¼Œstoryagentï¼Œæˆ‘æ­£åœ¨ä¸ºä¸€ä¸ªæ–°çš„ç”µå­ç»˜æœ¬æ„æ€ä¸€ä¸ªæ•…äº‹ã€‚æˆ‘å¸Œæœ›è¿™æ˜¯ä¸€ä¸ªå…³äºå‹è°Šå’Œå†’é™©çš„æ•…äº‹ï¼Œä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œåˆ†æˆä¸‰å¹•æ¥ç”Ÿæˆã€‚',
                    'ä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œåˆ†æˆ2å¹•æ¥ç”Ÿæˆã€‚', 'ä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ï¼Œ',
                    'å—¨ï¼Œstoryagentï¼Œæˆ‘æ­£åœ¨ä¸ºä¸€ä¸ªæ–°çš„ç”µå­ç»˜æœ¬æ„æ€ä¸€ä¸ªæ•…äº‹ã€‚æˆ‘å¸Œæœ›è¿™æ˜¯ä¸€ä¸ªå…³äºå‹è°Šå’Œå†’é™©çš„æ•…äº‹ï¼Œä¸»è§’æ˜¯ä¸€åªå‹‡æ•¢çš„å°ç‹ç‹¸å’Œå…¶ä»–å°åŠ¨ç‰©ã€‚'
                ],
                inputs=[user_input],
                examples_per_page=20,
                label="ç¤ºä¾‹",
                elem_id="chat-examples")

            steps = gr.Slider(
                minimum=1,
                maximum=max_scene,
                value=1,
                step=1,
                label='ç”Ÿæˆç»˜æœ¬çš„æ•°ç›®',
                interactive=True)

    stream_predict_input = [user_input, steps]
    stream_predict_output = [*output_image, *output_text]

    clean_outputs = [''] + [None] * max_scene + [''] * max_scene
    clean_outputs_target = [user_input, *output_image, *output_text]

    user_input.submit(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    submitBtn.click(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    submitBtn.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        generate_story_p,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    def clear_session():
        agent.reset()

    clear_session_button.click(fn=clear_session, inputs=[], outputs=[])
    clear_session_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    demo.title = "StoryAgent ğŸ"
    demo.queue(concurrency_count=10, status_update_rate='auto', api_open=False)
    demo.launch(show_api=False, share=True)
