{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clone代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/modelscope/modelscope-agent.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装特定依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd modelscope-agent && pip install -r requirements.txt\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本地部署llm\n",
    "modelscope提供模型本地启动服务功能。这里我们使用该功能，将模型部署成openai api兼容的接口。具体操作可参考如下：\n",
    "#### 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"from modelscope import snapshot_download; model_dir = snapshot_download('qwen/Qwen1.5-7B-Chat', cache_dir='qwen1.5-7b-chat');print(model_dir)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 部署模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在终端里执行下面的命令启动llm模型服务\n",
    "!MODELSCOPE_CACHE='demo/qwen1.5-7b-chat' python -m vllm.entrypoints.openai.api_server \\\n",
    "    --model qwen/Qwen1.5-7B-Chat --dtype=half --max-model-len 8192  --gpu-memory-utilization 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试部署\n",
    "测试模型服务，如果正确返回，说明模型服务部署完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:8000/v1/chat/completions \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{\n",
    "        \"model\": \"qwen/Qwen1.5-7B-Chat\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"写一篇春天为主题的作文\"}\n",
    "        ],\n",
    "        \"stop\": [\"<|im_end|>\", \"<|endoftext|>\"]\n",
    "    }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部署agent\n",
    "#### 拉起agent gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 另起一个终端窗口，后面将在这个终端里拉起gradio\n",
    "!cd modelscope-agent/apps/agentfabric\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编辑config/model_config.json， 增加如下配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"qwen1.5-7b-chat-vllm-local\": {\n",
    "        \"type\": \"openai\",\n",
    "        \"model\": \"qwen/Qwen1.5-7B-Chat\",\n",
    "        \"api_base\": \"http://localhost:8000/v1\",\n",
    "        \"is_chat\": true,\n",
    "        \"is_function_call\": false\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在agentfabric目录下执行如下命令拉起gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!GRADIO_SERVER_NAME=0.0.0.0 PYTHONPATH=../../  python app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后在浏览器中输入 服务器IP:7860打开即可看到如下界面。\n",
    "![Alt text](../docs/resource/local_deploy.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
