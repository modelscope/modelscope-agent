Q8：多卡环境，如何指定卡推理？

推理可以传递参数 device，pipeline 参数: device 设置 'gpu:0' 即可。

Q9：zero-shot 分类模型可以用下游的自己的数据作微调吗？

可以。如果您的数据 label 变化较大，出于追求模型效果，classifier 可以 init weight 处理。如果您的数据 label 变化不大，可以直接在 classifier 上继续微调。

Q10：在哪里可以看得到 ModelScope 教程和实战资料？

您可以查看 ModelScope 实战训练营，点击报名后即可查看所有录制的视频课程。

Q11：ModelScope 有没有已经搭好的 docker 镜像，以及我应该在哪里下载使用？

ModelScope 提供 GPU 镜像和 CPU 镜像，具体可在环境安装内查看最新版本镜像信息。

Q12：ModelScope 是否支持算法评测？

目前 API 支持单个模型的 finetune 和评测，批量评测功能还在持续建设中，您暂时可以写个脚本来实现。关于算法评测，可以参考这里。

Q13：ModelScope 是否会推出纯离线的 SDK 版本？

现在模型大部分还是需要基于服务端的算力支持，纯端上的模型的剪枝和转化可以需要用一些工具来解决，这部分工具能力还在规划开放中。

Q14：通过 SDK 上传数据集或模型时，报错“requests.exceptions.HTTPError: 400 Client Error: Bad Request for url:”怎么办？

您可以先检查下当前的 Library 版本，确认下是否为最新。然后检查下采用的 token 是否为 SDK token。若还不能解决该问题，请联系官方协助您解决。

Q15：使用官方镜像，但加载模型过程中会存在报错，应该怎么解决？
您可以先通过 pip list 等方式，对照环境安装内版本号看当前镜像是否为最新版本，若非最新版本，可更新后重试。若重试依然无法解决问题，请通过官方钉钉群联系我们。

Q16: 模型大文件上传遇到问题如何解决？
模型文件一般都比较大，我们通过 git lfs 管理模型中的大文件，首先确保您安装了正确版本的 git-lfs, 另外请确保您的大文件在文件列表中(.gitattributes 文件).
